{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3992718,"sourceType":"datasetVersion","datasetId":2369239}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-04T22:32:52.487636Z","iopub.execute_input":"2023-12-04T22:32:52.488007Z","iopub.status.idle":"2023-12-04T22:32:52.497413Z","shell.execute_reply.started":"2023-12-04T22:32:52.487974Z","shell.execute_reply":"2023-12-04T22:32:52.496476Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/stance-detection-dataset/fnc-1-master/scorer.py\n/kaggle/input/stance-detection-dataset/fnc-1-master/README.md\n/kaggle/input/stance-detection-dataset/fnc-1-master/train_stances.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/test_stances_unlabeled.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/train_bodies.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_stances.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/train_stances.random.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_bodies.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_stances_unlabeled.csv\n/kaggle/input/stance-detection-dataset/fnc-1-master/test_bodies.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing stock ml libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn import metrics\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, BertModel, BertConfig\n\n# Preparing for TPU usage\n# import torch_xla\n# import torch_xla.core.xla_model as xm\n# device = xm.xla_device()\n\n# # Setting up the device for GPU usage\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:52.498989Z","iopub.execute_input":"2023-12-04T22:32:52.499283Z","iopub.status.idle":"2023-12-04T22:32:52.613006Z","shell.execute_reply.started":"2023-12-04T22:32:52.499257Z","shell.execute_reply":"2023-12-04T22:32:52.612146Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#load data\ndf_body_train = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/train_bodies.csv\")\ndf_stance_train = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/train_stances.csv\")\ndf_body_test = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_bodies.csv\")\ndf_stance_test = pd.read_csv(\"/kaggle/input/stance-detection-dataset/fnc-1-master/competition_test_stances.csv\")\n\n\n# merge the tables by Body ID\ntrain_df = pd.merge(df_body_train, df_stance_train, on='Body ID', how='inner')\ntest_df = pd.merge(df_body_test, df_stance_test, on='Body ID', how='inner')\n\n# null_counts_train = train_df.isnull().sum() #no nulls\n# null_counts_test = test_df.isnull().sum()  #no nulls\n\ntotal_rows_train = len(train_df)\ntotal_rows_test = len(test_df)\n\nunique_body_ids_train = train_df['Body ID'].nunique()\nunique_body_ids_test = test_df['Body ID'].nunique()\n\nprint(\"TRAIN: Total number of rows: \",total_rows_train,\", Unique Body IDs:\",unique_body_ids_train)\nprint(\"TEST: Total number of rows: \",total_rows_test,\", Unique Body IDs:\",unique_body_ids_test)\n\n# print(train_df.head())\n# print(test_df.head())\n\n# convert the last column i.e. the categorical column to a one hot encoded list. \ntrain_df['list'] = pd.get_dummies(train_df['Stance'],columns=train_df.columns).astype(int).values.tolist()\nnew_df_train = train_df[['articleBody','Headline', 'list']].copy()\n# Passing colums as train.columns so that the encoding is consistent among train and test\ntest_df['list'] = pd.get_dummies(test_df['Stance'],columns=train_df.columns).astype(int).values.tolist()\nnew_df_test = test_df[['articleBody','Headline', 'list']].copy()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:52.614651Z","iopub.execute_input":"2023-12-04T22:32:52.614975Z","iopub.status.idle":"2023-12-04T22:32:53.092171Z","shell.execute_reply.started":"2023-12-04T22:32:52.614948Z","shell.execute_reply":"2023-12-04T22:32:53.091276Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"TRAIN: Total number of rows:  49972 , Unique Body IDs: 1683\nTEST: Total number of rows:  25413 , Unique Body IDs: 904\n","output_type":"stream"}]},{"cell_type":"code","source":"new_df_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:53.093284Z","iopub.execute_input":"2023-12-04T22:32:53.093573Z","iopub.status.idle":"2023-12-04T22:32:53.108005Z","shell.execute_reply.started":"2023-12-04T22:32:53.093537Z","shell.execute_reply":"2023-12-04T22:32:53.107104Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                         articleBody  \\\n0  A small meteorite crashed into a wooded area i...   \n1  A small meteorite crashed into a wooded area i...   \n2  A small meteorite crashed into a wooded area i...   \n3  A small meteorite crashed into a wooded area i...   \n4  A small meteorite crashed into a wooded area i...   \n\n                                            Headline          list  \n0  Soldier shot, Parliament locked down after gun...  [0, 0, 0, 1]  \n1  Tourist dubbed ‘Spider Man’ after spider burro...  [0, 0, 0, 1]  \n2  Luke Somers 'killed in failed rescue attempt i...  [0, 0, 0, 1]  \n3   BREAKING: Soldier shot at War Memorial in Ottawa  [0, 0, 0, 1]  \n4  Giant 8ft 9in catfish weighing 19 stone caught...  [0, 0, 0, 1]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>articleBody</th>\n      <th>Headline</th>\n      <th>list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Soldier shot, Parliament locked down after gun...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Tourist dubbed ‘Spider Man’ after spider burro...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Luke Somers 'killed in failed rescue attempt i...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>BREAKING: Soldier shot at War Memorial in Ottawa</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A small meteorite crashed into a wooded area i...</td>\n      <td>Giant 8ft 9in catfish weighing 19 stone caught...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_df_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:53.110241Z","iopub.execute_input":"2023-12-04T22:32:53.110515Z","iopub.status.idle":"2023-12-04T22:32:53.122378Z","shell.execute_reply.started":"2023-12-04T22:32:53.110491Z","shell.execute_reply":"2023-12-04T22:32:53.121369Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                         articleBody  \\\n0  Al-Sisi has denied Israeli reports stating tha...   \n1  Al-Sisi has denied Israeli reports stating tha...   \n2  Al-Sisi has denied Israeli reports stating tha...   \n3  Al-Sisi has denied Israeli reports stating tha...   \n4  Al-Sisi has denied Israeli reports stating tha...   \n\n                                            Headline          list  \n0  Apple installing safes in-store to protect gol...  [0, 0, 0, 1]  \n1  El-Sisi denies claims he'll give Sinai land to...  [1, 0, 0, 0]  \n2  Apple to keep gold Watch Editions in special i...  [0, 0, 0, 1]  \n3  Apple Stores to Keep Gold “Edition” Apple Watc...  [0, 0, 0, 1]  \n4  South Korean woman's hair 'eaten' by robot vac...  [0, 0, 0, 1]  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>articleBody</th>\n      <th>Headline</th>\n      <th>list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>Apple installing safes in-store to protect gol...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>El-Sisi denies claims he'll give Sinai land to...</td>\n      <td>[1, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>Apple to keep gold Watch Editions in special i...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>Apple Stores to Keep Gold “Edition” Apple Watc...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n      <td>South Korean woman's hair 'eaten' by robot vac...</td>\n      <td>[0, 0, 0, 1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"new_df_train['articleBody'].apply(lambda x: len(str(x).split())).max()","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:53.123455Z","iopub.execute_input":"2023-12-04T22:32:53.123824Z","iopub.status.idle":"2023-12-04T22:32:54.097321Z","shell.execute_reply.started":"2023-12-04T22:32:53.123795Z","shell.execute_reply":"2023-12-04T22:32:54.096315Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"4788"},"metadata":{}}]},{"cell_type":"code","source":"# Sections of config\n\n# Defining some key variables that will be used later on in the training\nMAX_LEN = 256\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 4\nEPOCHS = 4\nLEARNING_RATE = 1e-05\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:54.098595Z","iopub.execute_input":"2023-12-04T22:32:54.098909Z","iopub.status.idle":"2023-12-04T22:32:54.282614Z","shell.execute_reply.started":"2023-12-04T22:32:54.098881Z","shell.execute_reply":"2023-12-04T22:32:54.281613Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n\n    def __init__(self, dataframe, tokenizer, max_len):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.article_body = self.data[\"articleBody\"]\n        self.headline = self.data[\"Headline\"]\n        self.targets = self.data.list\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.article_body)\n\n    def __getitem__(self, index):\n        article_body = str(self.article_body[index])\n        article_body = \" \".join(article_body.split())\n        headline = str(self.headline[index])\n        headline = \" \".join(headline.split())\n\n        inputs = self.tokenizer(\n            article_body, \n            headline,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=True,\n            truncation='only_first', \n            return_overflowing_tokens=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n\n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:54.283955Z","iopub.execute_input":"2023-12-04T22:32:54.284243Z","iopub.status.idle":"2023-12-04T22:32:54.294499Z","shell.execute_reply.started":"2023-12-04T22:32:54.284218Z","shell.execute_reply":"2023-12-04T22:32:54.293689Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Creating the dataset and dataloader for the neural network\n\ntrain_dataset=new_df_train.sample(frac=1,random_state=200).reset_index(drop=True)\ntest_dataset=new_df_test.sample(frac=1,random_state=200).reset_index(drop=True)\n\n\n# print(\"FULL Dataset: {}\".format(new_df.shape))\nprint(\"TRAIN Dataset: {}\".format(train_dataset.shape))\nprint(\"TEST Dataset: {}\".format(test_dataset.shape))\n\ntraining_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\ntesting_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:54.295668Z","iopub.execute_input":"2023-12-04T22:32:54.296008Z","iopub.status.idle":"2023-12-04T22:32:54.324365Z","shell.execute_reply.started":"2023-12-04T22:32:54.295983Z","shell.execute_reply":"2023-12-04T22:32:54.323133Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"TRAIN Dataset: (49972, 3)\nTEST Dataset: (25413, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0\n                }\n\ntraining_loader = DataLoader(training_set, **train_params)\ntesting_loader = DataLoader(testing_set, **test_params)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:54.325814Z","iopub.execute_input":"2023-12-04T22:32:54.326182Z","iopub.status.idle":"2023-12-04T22:32:54.333708Z","shell.execute_reply.started":"2023-12-04T22:32:54.326147Z","shell.execute_reply":"2023-12-04T22:32:54.332637Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n\nclass BERTClass(torch.nn.Module):\n    def __init__(self):\n        super(BERTClass, self).__init__()\n        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased')\n        # Freeze the weights of the BERT layer\n        for param in self.l1.parameters():\n            param.requires_grad = False\n#         self.pre_classifier = torch.nn.Linear(768, 768)\n#         self.dropout = torch.nn.Dropout(0.3)\n#         self.classifier = torch.nn.Linear(768, 4)\n        self.l2 = torch.nn.Dropout(0.3)\n        self.l3 = torch.nn.Linear(768, 4)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids, return_dict=False)\n        output_2 = self.l2(output_1)\n        output = self.l3(output_2)\n        return output\n\nmodel = BERTClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:54.337124Z","iopub.execute_input":"2023-12-04T22:32:54.337415Z","iopub.status.idle":"2023-12-04T22:32:57.255596Z","shell.execute_reply.started":"2023-12-04T22:32:54.337390Z","shell.execute_reply":"2023-12-04T22:32:57.254598Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"BERTClass(\n  (l1): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (l2): Dropout(p=0.3, inplace=False)\n  (l3): Linear(in_features=768, out_features=4, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:57.257434Z","iopub.execute_input":"2023-12-04T22:32:57.258188Z","iopub.status.idle":"2023-12-04T22:32:57.263042Z","shell.execute_reply.started":"2023-12-04T22:32:57.258149Z","shell.execute_reply":"2023-12-04T22:32:57.261983Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:57.264640Z","iopub.execute_input":"2023-12-04T22:32:57.265055Z","iopub.status.idle":"2023-12-04T22:32:57.275264Z","shell.execute_reply.started":"2023-12-04T22:32:57.265015Z","shell.execute_reply":"2023-12-04T22:32:57.274251Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"loss_tracker = []\ndef train(epoch):\n    model.train()\n    for _,data in enumerate(training_loader, 0):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets)\n        if _%1000==0:\n            loss_tracker.append(loss)\n            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \ndef validation(epoch):\n    model.eval()\n    fin_targets=[]\n    fin_outputs=[]\n    with torch.no_grad():\n        for _, data in enumerate(testing_loader, 0):\n            ids = data['ids'].to(device, dtype = torch.long)\n            mask = data['mask'].to(device, dtype = torch.long)\n            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n            targets = data['targets'].to(device, dtype = torch.float)\n            outputs = model(ids, mask, token_type_ids)\n            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n    return fin_outputs, fin_targets","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:57.276415Z","iopub.execute_input":"2023-12-04T22:32:57.276737Z","iopub.status.idle":"2023-12-04T22:32:57.290459Z","shell.execute_reply.started":"2023-12-04T22:32:57.276700Z","shell.execute_reply":"2023-12-04T22:32:57.289614Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"accuracy_tracker = []\nf1_micro_tracker = []\nf1_macro_tracker = []\nprecision_tracker = []\nrecall_tracker = []\nmcc_tracker = []\nlogloss_tracker = []\nhammingloss_tracker = []\n\nfor epoch in range(EPOCHS):\n    print(\"Epoch \",epoch)\n    train(epoch)\n    outputs, targets = validation(epoch)\n    outputs = np.array(outputs) >= 0.5\n    accuracy = metrics.accuracy_score(targets, outputs)\n    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n    precision_score = metrics.precision_score(targets, outputs, average = 'samples', zero_division = 0)\n    recall_score = metrics.recall_score(targets, outputs, average = 'samples')\n    # MCC not supported for multiclass\n#     mcc_score = metrics.matthews_corrcoef(targets,outputs)\n    logloss_score = metrics.log_loss(targets, outputs)\n    hammingloss_score = metrics.hamming_loss(targets, outputs)\n    \n    accuracy_tracker.append(accuracy)\n    f1_micro_tracker.append(f1_score_micro)\n    f1_macro_tracker.append(f1_score_macro)\n    precision_tracker.append(precision_score)\n    recall_tracker.append(recall_score)\n#     mcc_tracker.append(mcc_score)\n    logloss_tracker.append(logloss_score)\n    hammingloss_tracker.append(hammingloss_score)\n    print(f\"Accuracy Score = {accuracy}\")\n    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n    print(f\"Precision = {precision_score}\")\n    print(f\"Recall = {recall_score}\")\n#     print(f\"MCC = {mcc_score}\")\n    print(f\"LogLoss = {logloss_score}\")\n    print(f\"Hamming Loss = {hammingloss_score}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-04T22:32:57.291666Z","iopub.execute_input":"2023-12-04T22:32:57.291957Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch  0\nEpoch: 0, Loss:  0.6539868116378784\nEpoch: 0, Loss:  0.3803189992904663\nEpoch: 0, Loss:  0.2370111644268036\nEpoch: 0, Loss:  0.32327479124069214\nEpoch: 0, Loss:  0.505055844783783\nEpoch: 0, Loss:  0.29159337282180786\nEpoch: 0, Loss:  0.2822578549385071\nAccuracy Score = 0.7099515995750206\nF1 Score (Micro) = 0.7538750783371632\nF1 Score (Macro) = 0.22110577394373104\nPrecision = 0.7099909495140283\nRecall = 0.7100302994530359\nLogLoss = 6.417605167195905\nHamming Loss = 0.11590524534686972\nEpoch  1\nEpoch: 1, Loss:  0.2268395572900772\nEpoch: 1, Loss:  0.3137916028499603\nEpoch: 1, Loss:  0.3585245609283447\nEpoch: 1, Loss:  0.1453838348388672\nEpoch: 1, Loss:  0.13214647769927979\nEpoch: 1, Loss:  0.1081865206360817\nEpoch: 1, Loss:  0.4101746380329132\nAccuracy Score = 0.6718608586156691\nF1 Score (Micro) = 0.7477445913987912\nF1 Score (Macro) = 0.22463732179206744\nPrecision = 0.6718608586156691\nRecall = 0.6718608586156691\nLogLoss = 4.793033791580611\nHamming Loss = 0.11332782434187227\nEpoch  2\nEpoch: 2, Loss:  0.5942239761352539\nEpoch: 2, Loss:  0.3273956775665283\nEpoch: 2, Loss:  0.25512611865997314\nEpoch: 2, Loss:  0.24589648842811584\nEpoch: 2, Loss:  0.16923627257347107\nEpoch: 2, Loss:  0.24862635135650635\nEpoch: 2, Loss:  0.5139930844306946\nAccuracy Score = 0.6781174989178766\nF1 Score (Micro) = 0.7521714460302911\nF1 Score (Macro) = 0.2995701345178484\nPrecision = 0.6781174989178766\nRecall = 0.6781174989178766\nLogLoss = 4.777541421590525\nHamming Loss = 0.11171447684256089\nEpoch  3\nEpoch: 3, Loss:  0.2707291543483734\nEpoch: 3, Loss:  0.36252403259277344\nEpoch: 3, Loss:  0.22095048427581787\nEpoch: 3, Loss:  0.11477947235107422\nEpoch: 3, Loss:  0.3636761009693146\nEpoch: 3, Loss:  0.1526191383600235\nEpoch: 3, Loss:  0.3219664394855499\n","output_type":"stream"}]},{"cell_type":"code","source":"np.savetxt('stance_bert_loss_tracker.txt',[tensor.cpu().detach().numpy() for tensor in loss_tracker],delimiter=',')\nnp.savetxt('stance_bert_accuracy_tracker.txt',accuracy_tracker,delimiter=',')\nnp.savetxt('stance_bert_f1_micro_tracker.txt',f1_micro_tracker,delimiter=',')\nnp.savetxt('stance_bert_f1_macro_tracker.txt',f1_macro_tracker,delimiter=',')\nnp.savetxt('stance_bert_precision_tracker.txt',precision_tracker,delimiter=',')\nnp.savetxt('stance_bert_recall_tracker.txt',recall_tracker,delimiter=',')\n# np.savetxt('stance_bert_mcc_tracker.txt',mcc_tracker,delimiter=',')\nnp.savetxt('stance_bert_logloss_tracker.txt',logloss_tracker,delimiter=',')\nnp.savetxt('stance_bert_f1_hammingloss_tracker.txt',hammingloss_tracker,delimiter=',')\n\nPkl_Filename = \"stance_detection_bert.pkl\"  \nimport pickle\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def validation(epoch):\n#     model.eval()\n#     fin_targets=[]\n#     fin_outputs=[]\n#     with torch.no_grad():\n#         for _, data in enumerate(testing_loader, 0):\n#             ids = data['ids'].to(device, dtype = torch.long)\n#             mask = data['mask'].to(device, dtype = torch.long)\n#             token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n#             targets = data['targets'].to(device, dtype = torch.float)\n#             outputs = model(ids, mask, token_type_ids)\n#             fin_targets.extend(targets.cpu().detach().numpy().tolist())\n#             fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n#     return fin_outputs, fin_targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for epoch in range(EPOCHS):\n#     print(\"Epoch \",epoch)\n#     outputs, targets = validation(epoch)\n#     outputs = np.array(outputs) >= 0.5\n#     accuracy = metrics.accuracy_score(targets, outputs)\n#     f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n#     f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n#     print(f\"Accuracy Score = {accuracy}\")\n#     print(f\"F1 Score (Micro) = {f1_score_micro}\")\n#     print(f\"F1 Score (Macro) = {f1_score_macro}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}